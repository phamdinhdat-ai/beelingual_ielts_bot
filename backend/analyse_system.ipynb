{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctai-datpd-l/anaconda3/envs/ai_agents/lib/python3.11/site-packages/pydantic/_internal/_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/home/ctai-datpd-l/anaconda3/envs/ai_agents/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from typing import Iterator, List\n",
    "# CrewAI imports\n",
    "\n",
    "# LLM\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "# from agent.utils.load_documents import covert_document\n",
    "from agent.tools.retrieve_tool import RetrieveTool, IngestTool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "# from docling.document_converter import DocumentConverter\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredWordDocumentLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = [\"data/2501.07329v2.pdf\",\n",
    "             \"data/ielts_listening_practice_test_pdf_1_1_1ae068b05d.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DocumentPDFLoader(BaseLoader):\n",
    "    \n",
    "#     def __init__(self, filepath: List[str]) -> None: \n",
    "#         self._filepath = filepath if isinstance(filepath, list) else [filepath]\n",
    "#         self._coverter = DocumentConverter()\n",
    "    \n",
    "#     def lazy_load (self)->Iterator[Document]:\n",
    "#         for file in self._filepath:\n",
    "#             dl = self._coverter.convert(file).document\n",
    "#             text = dl.export_to_markdown()\n",
    "#             yield Document(page_content=text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_loader = DocumentPDFLoader(file_path)\n",
    "\n",
    "class DocumentPDFLoader(BaseLoader):\n",
    "    def __init__(self, filepath: List[str]) -> None: \n",
    "        self._filepath = filepath if isinstance(filepath, list) else [filepath]\n",
    "        self._loaders = [PyPDFLoader(file) for file in self._filepath]\n",
    "    \n",
    "    def lazy_load (self)->Iterator[Document]:\n",
    "        for loader in self._loaders:\n",
    "            for doc in loader.load():\n",
    "                yield doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = DocumentPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = chunker.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Skia/PDF m109 Google Docs Renderer',\n",
       " 'creator': 'PyPDF',\n",
       " 'creationdate': '',\n",
       " 'title': 'ielts-listening-practice-test-pdf-1',\n",
       " 'source': 'data/ielts_listening_practice_test_pdf_1_1_1ae068b05d.pdf',\n",
       " 'total_pages': 7,\n",
       " 'page': 3,\n",
       " 'page_label': '4'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[40].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc.page_content for doc in text_chunks]\n",
    "metadata = [doc.metadata for doc in text_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # Load environment variables if needed (e.g., API keys for other tools)\n",
    "TEST_COLLECTION_NAME = \"agent_test_docs\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\" # Ensure this model is available locally\n",
    "PERSIST_DIR = \"./_agent_test_chroma_db\"\n",
    "LLM_MODEL = \"deepseek-r1:1.5b\" # Or your preferred Ollama model\n",
    "# llm = ChatOllama(model='deepseek-r1:1.5b', temperature=0.2, max_tokens=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joint Automatic Speech Recognition And Structure\\nLearning For Better Speech Understanding\\nJiliang Hu1, Zuchao Li 2,*, Mengjia Shen 3, Haojun Ai 1, Sheng Li 4, Jun Zhang 3\\n1Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education,\\nSchool of Cyber Science and Engineering, Wuhan University, Wuhan, China,\\n2School of Computer Science, Wuhan University, Wuhan, China,\\n3Wuhan Second Ship Design and Research Institute, Wuhan, China,\\n4National Institute of Information and Communications Technology, Japan.\\nAbstract—Spoken language understanding (SLU) is a structure\\nprediction task in the field of speech. Recently, many works\\non SLU that treat it as a sequence-to-sequence task have\\nachieved great success. However, This method is not suitable\\nfor simultaneous speech recognition and understanding. In this\\npaper, we propose a joint speech recognition and structure\\nlearning framework (JSRSL), an end-to-end SLU model based'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"Initializes LLM, Tools, and cleans up old DB.\"\"\"\n",
    "    logger.info(\"--- Setting up test environment ---\")\n",
    "\n",
    "    try:\n",
    "        # Initialize LLM\n",
    "        logger.info(f\"Loading LLM: {LLM_MODEL}\")\n",
    "        llm = ChatOllama(model=LLM_MODEL, temperature=0.1)\n",
    "        # Simple check if LLM is accessible (optional, Ollama might not have a direct check)\n",
    "        # llm.invoke(\"Hi\")\n",
    "        logger.info(\"LLM loaded successfully.\")\n",
    "\n",
    "        # Initialize Tools\n",
    "        logger.info(\"Initializing RAG Tools...\")\n",
    "        retriever_tool = RetrieveTool(\n",
    "            embedding_model_name=EMBEDDING_MODEL,\n",
    "            persist_dir=PERSIST_DIR\n",
    "        )\n",
    "        ingest_tool = IngestTool(retriever_tool=retriever_tool)\n",
    "        logger.info(\"RAG Tools initialized successfully.\")\n",
    "\n",
    "        return llm, retriever_tool, ingest_tool\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set up environment: {e}\", exc_info=True)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7350/4034160067.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=LLM_MODEL, temperature=0.1)\n",
      "/home/ctai-datpd-l/anaconda3/envs/ai_agents/lib/python3.11/site-packages/chromadb/db/impl/sqlite.py:111: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\n",
      "2025-05-05 21:06:24,546 - 127360389907520 - sqlite.py-sqlite:111 - WARNING: ⚠️ It looks like you upgraded from a version below 0.6 and could benefit from vacuuming your database. Run chromadb utils vacuum --help for more information.\n"
     ]
    }
   ],
   "source": [
    "llm, retriever_tool, ingest_tool = setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, ingest_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 22:15:40,779 - 127360389907520 - retrieve_tool.py-retrieve_tool:315 - WARNING: Collection 'dat1' not found or error retrieving it: Collection dat1 does not exist.\n"
     ]
    }
   ],
   "source": [
    "out = retriever_tool._get_collection(collection_name='dat1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:06:27,810 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"--- Defining Knowledge Base Manager Agent ---\")\n",
    "kb_manager_agent = Agent(\n",
    "    role='Knowledge Base Manager',\n",
    "    goal=f\"Efficiently manage and retrieve information from the company's knowledge base stored in ChromaDB. Use the provided tools to ingest new documents into specific collections and retrieve relevant information based on queries.\",\n",
    "    backstory=(\n",
    "        \"You are an expert AI assistant responsible for maintaining the accuracy and accessibility \"\n",
    "        \"of the company's document knowledge base. You meticulously ingest new information using the \"\n",
    "        \"'ChromaDB Document Ingest Tool' and expertly query the database using the \"\n",
    "        \"'ChromaDB Retriever Tool' to answer questions. Always specify the correct collection name.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    verbose=True, # Set to True to see LLM reasoning and tool calls\n",
    "    allow_delegation=False,\n",
    "    \n",
    "    # memory=True # Optional: Enable memory for conversation context if needed\n",
    ")\n",
    "logger.info(f\"Agent '{kb_manager_agent.role}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_repr = repr(docs)\n",
    "metas_repr = repr(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ingest = Task(\n",
    "        description=(\n",
    "            f\"Ingest the following set of documents into the '{TEST_COLLECTION_NAME}' collection \"\n",
    "            f\"using the 'ChromaDB Document Ingest Tool'. Ensure you pass both the document texts \"\n",
    "            f\"and their corresponding metadata.\\n\\n\"\n",
    "            f\"Documents to ingest: {docs_repr}\\n\"\n",
    "            f\"Associated Metadatas: {metas_repr}\"\n",
    "        ),\n",
    "        expected_output=(\n",
    "            f\"Confirmation that {len(docs)} documents were successfully ingested \"\n",
    "            f\"into the '{TEST_COLLECTION_NAME}' collection.\"\n",
    "        ),\n",
    "        agent=kb_manager_agent,\n",
    "        tools=[ingest_tool] # Optional: Limit tools for this specific task\n",
    "    )\n",
    "logger.info(\"Ingestion task defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the Joint Automatic Speech Recognition and Machine Translation (JASR-MT) task?\"\n",
    "task_retrieve = Task(\n",
    "    description=(\n",
    "        f\"Search the '{TEST_COLLECTION_NAME}' collection using the 'ChromaDB Retriever Tool' to find information relevant to the following query: '{query}'. \"\n",
    "        f\"Retrieve the top 3 most relevant documents using MMR for diversity. \" # Explicitly guide MMR usage\n",
    "        f\"Present the content of the retrieved documents clearly.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A summary or list of the content from the top 3 relevant documents found in the \"\n",
    "        f\"'{TEST_COLLECTION_NAME}' collection related to '{query}', retrieved using MMR.\"\n",
    "    ),\n",
    "    agent=kb_manager_agent,\n",
    "    context=[task_ingest], # Make this task depend on the ingestion task\n",
    "    tools=[retriever_tool] # Optional: Limit tools for this specific task\n",
    ")\n",
    "logger.info(\"Retrieval task defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:06:27,884 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reflection_agent = Agent(\n",
    "    role='Reflection Agent',\n",
    "    goal=\"Reflect on the tasks and provide insights.\",\n",
    "    backstory=(\n",
    "        \"You are an AI assistant designed to reflect on the tasks performed by the Knowledge Base Manager. \"\n",
    "        \"Your role is to analyze the ingestion and retrieval processes, ensuring they align with the company's goals.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[],\n",
    "    verbose=True, # Set to True to see LLM reasoning and tool calls\n",
    "    allow_delegation=False,\n",
    ")\n",
    "logger.info(\"Reflection agent created.\")\n",
    "reflection_task = Task(\n",
    "    description=(\n",
    "        \"Reflect on the tasks performed by the Knowledge Base Manager. \"\n",
    "        \"Analyze the ingestion and retrieval processes, ensuring they align with the company's goals.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"Insights and analysis of the ingestion and retrieval processes, \"\n",
    "        \"ensuring they align with the company's goals.\"\n",
    "    ),\n",
    "    agent=reflection_agent,\n",
    "    context=[task_ingest, task_retrieve], # Make this task depend on both ingestion and retrieval tasks\n",
    "    tools=[] # No tools needed for reflection\n",
    ")\n",
    "logger.info(\"Reflection task defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:06:27,908 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Create and Run Crew\n",
    "logger.info(\"--- Creating and Running the Crew ---\")\n",
    "company_knowledge_crew = Crew(\n",
    "    agents=[kb_manager_agent],\n",
    "    tasks=[task_ingest, task_retrieve],\n",
    "    process=Process.sequential, # Ensure tasks run in order: ingest then retrieve\n",
    "    verbose=True # Use verbose=2 to see detailed LLM thoughts and tool calls\n",
    ")\n",
    "\n",
    "# result = company_knowledge_crew.kickoff()\n",
    "\n",
    "# logger.info(\"--- Crew Execution Finished ---\")\n",
    "# print(\"\\n\\n===== Final Crew Result =====\")\n",
    "# print(result)\n",
    "# print(\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Result: \\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from crewai import Agent, Task, Crew, Process\n",
    "# from crewai_tools import BaseTool, SerperDevTool\n",
    "# from langchain_community.chat_models.ollama import ChatOllama\n",
    "# from agent.config.load_config import agents_config\n",
    "# from agent.tools.nl2sql_tool import NL2SQLTool, ValidateSQLQueryTool\n",
    "# from dotenv import load_dotenv\n",
    "# from typing import List, Optional, Dict, Any\n",
    "# import chromadb\n",
    "# from os.path import dirname, join, abspath\n",
    "\n",
    "# # Import the retrieval tools\n",
    "# from agent.tools.retrieve_tool import RetrieveTool, IngestTool\n",
    "\n",
    "# # Load environment variables\n",
    "# env_path = join(dirname(dirname(abspath(__file__))), '.env')\n",
    "# load_dotenv(env_path)\n",
    "\n",
    "# class MultiAgentSystem:\n",
    "#     \"\"\"\n",
    "#     A multi-agent system using CrewAI framework.\n",
    "#     Integrates company, customer service, HR, and recommender agents.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, model_name: str = \"deepseek-r1:1.5b\"):\n",
    "#         \"\"\"\n",
    "#         Initialize the multi-agent system with specified LLM model.\n",
    "        \n",
    "#         Args:\n",
    "#             model_name: Name of the LLM model to use across agents\n",
    "#         \"\"\"\n",
    "#         self.model_name = model_name\n",
    "#         self.llm = self._load_llm(model_name)\n",
    "        \n",
    "#         # Initialize tools\n",
    "#         self.tools = self._setup_tools()\n",
    "        \n",
    "#         # Initialize agents\n",
    "#         self.agents = self._setup_agents()\n",
    "        \n",
    "#         # Create crew\n",
    "#         self.crew = self._setup_crew()\n",
    "    \n",
    "#     def _load_llm(self, model_name: str):\n",
    "#         \"\"\"Load the language model.\"\"\"\n",
    "#         return ChatOllama(model=model_name, temperature=0.2, max_tokens=2000)\n",
    "    \n",
    "#     def _setup_tools(self) -> Dict[str, List[BaseTool]]:\n",
    "#         \"\"\"Set up tools for each agent.\"\"\"\n",
    "#         # Common tools\n",
    "#         serper_api_key = os.environ.get('SERPER_API_KEY')\n",
    "#         search_tool = SerperDevTool(api_key=serper_api_key) if serper_api_key else None\n",
    "#         nl2sql_tool = NL2SQLTool()\n",
    "#         validate_sql_tool = ValidateSQLQueryTool()\n",
    "        \n",
    "#         # Retrieval tools\n",
    "#         retriever_tool = RetrieveTool(embedding_model_name=\"all-MiniLM-L6-v2\")\n",
    "#         ingest_tool = IngestTool(retriever_tool=retriever_tool)\n",
    "        \n",
    "#         # Define tool sets for each agent\n",
    "#         return {\n",
    "#             \"company_agent\": [tool for tool in [search_tool, nl2sql_tool, validate_sql_tool, retriever_tool, ingest_tool] if tool],\n",
    "#             \"customer_service_agent\": [tool for tool in [search_tool, nl2sql_tool, validate_sql_tool, retriever_tool] if tool],\n",
    "#             \"hr_agent\": [tool for tool in [search_tool, nl2sql_tool, retriever_tool] if tool],\n",
    "#             \"naive_agent\": [tool for tool in [search_tool, retriever_tool] if tool],\n",
    "#             \"recommender_agent\": [tool for tool in [search_tool, retriever_tool] if tool]\n",
    "#         }\n",
    "    \n",
    "#     def _setup_agents(self) -> Dict[str, Agent]:\n",
    "#         \"\"\"Set up all agents with their tools and configurations.\"\"\"\n",
    "#         agents = {}\n",
    "        \n",
    "#         # Create each agent using their config\n",
    "#         for agent_type in [\"company_agent\", \"customer_service_agent\", \"hr_agent\", \"naive_agent\", \"recommender_agent\"]:\n",
    "#             config = agents_config.get(agent_type, {})\n",
    "#             agents[agent_type] = Agent(\n",
    "#                 role=config.get('role', f\"{agent_type.replace('_', ' ').title()}\"),\n",
    "#                 goal=config.get('goal', \"Help the company achieve its objectives\"),\n",
    "#                 backstory=config.get('backstory', \"An experienced professional in the field\"),\n",
    "#                 verbose=config.get('verbose', True),\n",
    "#                 allow_delegation=config.get('allow_delegation', False),\n",
    "#                 tools=self.tools.get(agent_type, []),\n",
    "#                 llm=self.llm\n",
    "#             )\n",
    "        \n",
    "#         return agents\n",
    "    \n",
    "#     def _setup_crew(self) -> Crew:\n",
    "#         \"\"\"Set up the crew with all agents and their tasks.\"\"\"\n",
    "#         # Define tasks for each agent\n",
    "#         company_task = Task(\n",
    "#             description=\"Analyze company data and make strategic decisions\",\n",
    "#             agent=self.agents[\"company_agent\"],\n",
    "#             expected_output=\"Strategic analysis and recommendations for the company\"\n",
    "#         )\n",
    "        \n",
    "#         customer_task = Task(\n",
    "#             description=\"Address customer inquiries and improve satisfaction\",\n",
    "#             agent=self.agents[\"customer_service_agent\"],\n",
    "#             expected_output=\"Customer service report and satisfaction improvement plan\"\n",
    "#         )\n",
    "        \n",
    "#         hr_task = Task(\n",
    "#             description=\"Manage employee relations and recruitment\",\n",
    "#             agent=self.agents[\"hr_agent\"],\n",
    "#             expected_output=\"HR management report and recruitment strategy\"\n",
    "#         )\n",
    "        \n",
    "#         recommender_task = Task(\n",
    "#             description=\"Provide personalized recommendations to customers\",\n",
    "#             agent=self.agents[\"recommender_agent\"],\n",
    "#             expected_output=\"Customer recommendation system plan and implementation strategy\"\n",
    "#         )\n",
    "        \n",
    "#         # Create crew with all agents and tasks\n",
    "#         return Crew(\n",
    "#             agents=list(self.agents.values()),\n",
    "#             tasks=[company_task, customer_task, hr_task, recommender_task],\n",
    "#             verbose=2,\n",
    "#             process=Process.sequential  # Can be changed to Process.hierarchical if needed\n",
    "#         )\n",
    "    \n",
    "#     def run(self, query: str) -> str:\n",
    "#         \"\"\"\n",
    "#         Run the multi-agent system with a specific query.\n",
    "        \n",
    "#         Args:\n",
    "#             query: User query to process across agents\n",
    "            \n",
    "#         Returns:\n",
    "#             str: Results from the crew's execution\n",
    "#         \"\"\"\n",
    "#         # You could customize the tasks or crew configuration based on the query\n",
    "#         result = self.crew.kickoff(inputs={\"query\": query})\n",
    "#         return result\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize the multi-agent system\n",
    "#     system = MultiAgentSystem(model_name=\"deepseek-r1:1.5b\")\n",
    "    \n",
    "#     # Example document ingestion for testing the retrieval tool\n",
    "#     documents = [\n",
    "#         \"Our company specializes in AI-powered solutions for businesses.\",\n",
    "#         \"Customer satisfaction is our top priority, with 24/7 support available.\",\n",
    "#         \"The HR department handles recruitment, onboarding, and employee relations.\",\n",
    "#         \"Our recommendation engine uses machine learning to suggest products.\",\n",
    "#         \"Company policies include flexible working hours and remote options.\"\n",
    "#     ]\n",
    "    \n",
    "#     metadatas = [\n",
    "#         {\"category\": \"company_info\", \"department\": \"general\"},\n",
    "#         {\"category\": \"customer_service\", \"department\": \"support\"},\n",
    "#         {\"category\": \"hr\", \"department\": \"human_resources\"},\n",
    "#         {\"category\": \"technology\", \"department\": \"engineering\"},\n",
    "#         {\"category\": \"policy\", \"department\": \"human_resources\"}\n",
    "#     ]\n",
    "    \n",
    "#     # Access company agent and ingest sample documents\n",
    "#     retriever_tool = next((t for t in system.tools[\"company_agent\"] if isinstance(t, RetrieveTool)), None)\n",
    "#     if retriever_tool:\n",
    "#         retriever_tool.ingest_documents(\n",
    "#             documents=documents,\n",
    "#             collection_name=\"company_docs\",\n",
    "#             metadatas=metadatas\n",
    "#         )\n",
    "    \n",
    "#     # Run system with a test query\n",
    "#     result = system.run(\"What are our company's HR policies and how can we improve employee satisfaction?\")\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPER_API_KEY\"] = \"a6ce4b5fc4ef3f9754144d519ecf9e418bc1c7bc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrieveTool(name='ChromaDB Retriever Tool', description=\"Tool Name: ChromaDB Retriever Tool\\nTool Arguments: {'query': {'description': None, 'type': 'str'}, 'collection_name': {'description': None, 'type': 'str'}, 'top_k': {'description': None, 'type': 'int'}, 'use_mmr': {'description': None, 'type': 'bool'}, 'mmr_diversity': {'description': None, 'type': 'float'}}\\nTool Description: Retrieves relevant information from a specified ChromaDB collection. Can use standard similarity search or Maximum Marginal Relevance (MMR) for diversity.\", args_schema=<class 'abc.RetrieveToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x73d524542980>, result_as_answer=False, input_schema=<class 'agent.tools.retrieve_tool.RetrieveInput'>, persist_dir='./_agent_test_chroma_db')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools Initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctai-datpd-l/anaconda3/envs/ai_agents/lib/python3.11/site-packages/chromadb/types.py:144: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields  # pydantic 2.x\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
    "import operator\n",
    "from agent.utils.helper_function import extract_clean_json\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.tools import Tool\n",
    "# from crewai_tools import DuckDuckGoSearchRun # Re-use crewai tool directly\n",
    "from crewai_tools import SerperDevTool\n",
    "# For Customer Retriever (Example using FAISS)\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.tools.vectorstore.tool import VectorStoreQATool\n",
    "\n",
    "# from langgraph.graph import StateGraph, END\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver # For state persistence/debugging if needed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# --- Initialize LLM ---\n",
    "# Using a more capable model might be beneficial for classification and reflection\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0.2, num_predict=2000)\n",
    "\n",
    "# --- Initialize Tools ---\n",
    "search_tool = SerperDevTool(n_results=2)\n",
    "\n",
    "# --- Mock Customer Database & Retriever Tool ---\n",
    "# In a real scenario, connect to your actual database/vector store\n",
    "customer_data = {\n",
    "    \"cust123\": [\n",
    "        Document(page_content=\"Customer John Doe. Premium plan member since 2022. Last interaction: support ticket #5678 resolved.\", metadata={\"customer_id\": \"cust123\", \"source\": \"crm\"}),\n",
    "        Document(page_content=\"John Doe purchased Product X in Jan 2023 and Product Y in Nov 2023.\", metadata={\"customer_id\": \"cust123\", \"source\": \"orders\"}),\n",
    "    ],\n",
    "    \"cust456\": [\n",
    "        Document(page_content=\"Customer Jane Smith. Basic plan member since 2023. No open support tickets.\", metadata={\"customer_id\": \"cust456\", \"source\": \"crm\"}),\n",
    "    ]\n",
    "}\n",
    "# Flatten documents for indexing\n",
    "all_docs = [doc for docs in customer_data.values() for doc in docs]\n",
    "\n",
    "if all_docs:\n",
    "    # embeddings = OpenAIEmbeddings()\n",
    "    embeddings = OllamaEmbeddings(model=\"hf.co/CompendiumLabs/bge-base-en-v1.5-gguf:latest\")\n",
    "    vector_store = Chroma.from_documents(documents=all_docs, embedding=embeddings, persist_directory=PERSIST_DIR, collection_name=TEST_COLLECTION_NAME)\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 2}) # Retrieve top 2 docs\n",
    "\n",
    "    customer_retriever_tool = VectorStoreQATool(\n",
    "        name=\"customer_info_retriever\",\n",
    "        description=\"Searches and returns information about a specific customer from the customer database based on their ID.\",\n",
    "        vectorstore=vector_store,\n",
    "        llm=llm # The tool itself can use an LLM for QA over retrieved docs\n",
    "    )\n",
    "    # Note: This tool needs the query to implicitly or explicitly contain the customer ID for filtering,\n",
    "    # or the retriever needs more sophisticated filtering setup.\n",
    "    # For simplicity here, we'll assume the query passed to the tool includes context like \"for customer cust123\".\n",
    "else:\n",
    "    # Create a dummy tool if no customer data exists\n",
    "    def dummy_retriever_func(query: str):\n",
    "        return \"No customer data available for retrieval.\"\n",
    "    customer_retriever_tool = Tool(\n",
    "        name=\"customer_info_retriever\",\n",
    "        description=\"Searches and returns information about a specific customer. Currently, no data is loaded.\",\n",
    "        func=dummy_retriever_func\n",
    "    )\n",
    "\n",
    "print(\"Tools Initialized.\")\n",
    "# print(f\"Customer Retriever Tool Ready: {customer_retriever_tool.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.vectorstore.tool import VectorStoreQATool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:08:16,817 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "2025-05-05 21:08:16,821 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "2025-05-05 21:08:16,824 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "CrewAI Agent Definitions Ready (for conceptual reference).\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent as CrewAgent # Alias to avoid confusion with node names\n",
    "\n",
    "# Agent 1: Company Agent (Definition)\n",
    "company_agent_def = CrewAgent(\n",
    "    role='Company Information Specialist',\n",
    "    goal='Provide accurate information about the company (e.g., Google) including location, products, services, history, and mission, based on search results and internal knowledge.',\n",
    "    backstory='You are an AI assistant dedicated to representing the company accurately and helpfully to external queries. You use search tools to find the latest public information.',\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Agent 2: Customer Agent (Definition)\n",
    "customer_agent_def = CrewAgent(\n",
    "    role='Customer Support Agent',\n",
    "    goal='Answer customer-specific questions by retrieving their information from the customer database using their customer ID. Handle queries about plans, purchase history, support tickets etc.',\n",
    "    backstory='You are a helpful customer support agent with access to the customer database. You must use the customer ID provided to retrieve relevant information using your specialized tool.',\n",
    "    tools=[search_tool, retriever_tool], # Has retriever and search\n",
    "    llm=llm,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Agent 3: Naive Agent (Definition)\n",
    "naive_agent_def = CrewAgent(\n",
    "    role='General Knowledge Assistant',\n",
    "    goal='Answer general knowledge questions or queries that do not fall under specific company or customer information categories. Use search tools to find relevant information online.',\n",
    "    backstory='You are a general-purpose AI assistant capable of answering a wide range of topics by searching the internet.',\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"CrewAI Agent Definitions Ready (for conceptual reference).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task, Crew, Process\n",
    "from typing import List, Dict, Any, Optional, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph State Defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AgentState(TypedDict):\n",
    "    original_query: str\n",
    "    customer_id: Optional[str]\n",
    "    rewritten_query: str\n",
    "    classified_agent: Literal[\"Company\", \"Customer\", \"Naive\", \"Unknown\"]\n",
    "    agent_response: str\n",
    "    reflection: str\n",
    "    is_final: bool\n",
    "    error: Optional[str]\n",
    "    retry_count: int\n",
    "    suggested_questions: List[str]  # New field for suggested questions\n",
    "\n",
    "\n",
    "print(\"LangGraph State Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query_node(state: AgentState):\n",
    "    \"\"\"Rewrites the user query and classifies which agent should handle it.\"\"\"\n",
    "    logger.info(\"--- Node: Rewriter ---\")\n",
    "    if state.get(\"customer_id\"):\n",
    "        logger.info(f\"Customer ID found: {state['customer_id']}\")\n",
    "        return {\n",
    "                    \"rewritten_query\": state['original_query'], # No rewriting needed\n",
    "                    \"classified_agent\": \"Customer\", # Default to Customer if customer_id is present\n",
    "                    \"customer_id\": state['customer_id'], # Use state customer_id directly\n",
    "                    \"error\": None\n",
    "                }\n",
    "\n",
    "    query = state['original_query']\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert query processor. Your tasks are:\n",
    "    1.  Correct any spelling mistakes in the user query.\n",
    "    2.  Rephrase the query for maximum clarity if necessary.\n",
    "    3.  Classify the query's intent to determine the best agent to handle it:\n",
    "        - 'Company': For questions about a specific company's details (location, products, services, mission etc.). Assume the company is 'Google' if not specified.\n",
    "        - 'Customer': For questions related to a specific customer's account, history, plan, support tickets etc. These queries MUST contain or imply a customer ID.\n",
    "        - 'Naive': For general knowledge questions, queries unrelated to the company or a specific customer.\n",
    "        - 'Unknown': If the query is ambiguous or cannot be clearly classified.\n",
    "    4. Extract any customer ID mentioned (like cust123, user45, id: 7890). Return null if no ID is found.\n",
    "    Provide your output in the specified JSON format.\n",
    "    For example, for the query 'What is the status of my order with customer ID cust123?', your output should be:\n",
    "    <output>\n",
    "    {{\n",
    "        \"rewritten_query\": \"What is the status of my order?\",\n",
    "        \"agent_classification\": \"Customer\",\n",
    "        \"extracted_customer_id\": \"cust123\"\n",
    "    }}\n",
    "    </output>\n",
    "    If no customer ID is found, return null for that field.\n",
    "    If the query is not clear or cannot be classified, return 'Unknown' for the agent classification and null for the customer ID.\n",
    "    Your output should be a JSON object with the following fields:\n",
    "\n",
    "    {{\n",
    "        \"rewritten_query\": \"<corrected and clarified query>\",\n",
    "        \"agent_classification\": \"<Company|Customer|Naive|Unknown>\",\n",
    "        \"extracted_customer_id\": \"<customer ID or null>\"\n",
    "\n",
    "    }}\n",
    "\n",
    "    **CRITICAL:** You MUST format your output ONLY as a JSON object that strictly adheres to the following schema. Do NOT include any other text, explanations, or markdown formatting like ```json ``` around the JSON object itself.\"\"\"\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Process the following user query: {query}\")\n",
    "    ])\n",
    "\n",
    "    # Use OpenAI Functions for structured output\n",
    "    rewriter_chain = prompt | llm\n",
    "\n",
    "    try:\n",
    "        response = rewriter_chain.invoke({\"query\": query})\n",
    "        logger.info(response.content)\n",
    "        response = extract_clean_json(response.content)\n",
    "        if response:\n",
    "                # response = json.loads(json_str)\n",
    "                print(f\"Rewriter Output: {response}\")\n",
    "                return {\n",
    "                    \"rewritten_query\": response['rewritten_query'],\n",
    "                    \"classified_agent\": response['agent_classification'],\n",
    "                    \"customer_id\": response.get('extracted_customer_id') or state.get('customer_id'), # Prioritize extracted, fallback to state\n",
    "                    \"error\": None\n",
    "                }\n",
    "        else:\n",
    "            print(\"Rewriter output was not valid JSON.\")\n",
    "            return {\n",
    "                \"rewritten_query\": query,  # Fallback to original query\n",
    "                \"classified_agent\": \"Unknown\",\n",
    "                \"customer_id\": None,\n",
    "                \"error\": \"Invalid JSON response from rewriter.\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Rewriter node: {e}\")\n",
    "        return {\"error\": f\"Failed to process query: {e}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"original_query\": \"What is the mission of Google?\",\n",
    "    \"customer_id\": None,\n",
    "    \"rewritten_query\": \"\",\n",
    "    \"classified_agent\": \"\",\n",
    "    \"agent_response\": \"\",\n",
    "    \"reflection\": \"\",\n",
    "    \"is_final\": False,\n",
    "    \"error\": None,\n",
    "    \"retry_count\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewriter Output: {'rewritten_query': 'What is the mission of Google?', 'agent_classification': 'Naive', 'extracted_customer_id': None}\n"
     ]
    }
   ],
   "source": [
    "response = rewrite_query_node(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rewritten_query': 'What is the mission of Google?',\n",
       " 'classified_agent': 'Naive',\n",
       " 'customer_id': None,\n",
       " 'error': None}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.rewrite_query_node(state: __main__.AgentState)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_query_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execute_agent_node(state: AgentState, agent_def: CrewAgent, agent_name: str, ):\n",
    "    \"\"\"Generic function to execute the logic of a specific agent.\"\"\"\n",
    "    print(f\"--- Node: Execute {agent_name} Agent ---\")\n",
    "    if state.get(\"error\"): return {} # Don't run if prior error\n",
    "\n",
    "    query = state['rewritten_query']\n",
    "    customer_id = state.get('customer_id') # Relevant for Customer agent\n",
    "\n",
    "    # Construct a prompt using the agent's definition\n",
    "    prompt_messages = [\n",
    "        SystemMessage(content=f\"Role: {agent_def.role}\\nGoal: {agent_def.goal}\\nBackstory: {agent_def.backstory}\"),\n",
    "        HumanMessage(content=f\"User Query: {query}\")\n",
    "    ]\n",
    "    if agent_name == \"Customer\" and customer_id:\n",
    "         prompt_messages.append(HumanMessage(content=f\"Context: Apply this query to customer ID: {customer_id}.\"))\n",
    "    elif agent_name == \"Customer\" and not customer_id:\n",
    "         return {\"agent_response\": \"Cannot answer customer question without a Customer ID.\", \"error\": \"Missing Customer ID\"}\n",
    "\n",
    "\n",
    "    # Simplified tool handling for LangGraph node\n",
    "    # A more robust implementation would use LangChain's agent executors or tool calling\n",
    "    available_tools = {tool.name: tool for tool in agent_def.tools}\n",
    "    tool_response = \"\"\n",
    "\n",
    "    # Basic tool check (can be expanded)\n",
    "    # This is a placeholder - real tool use requires more complex agent logic (like ReAct or OpenAI Functions Agent)\n",
    "    if \"duckduckgo_search\" in available_tools and agent_name != \"Customer\": # Example: Use search for non-customer\n",
    "        try:\n",
    "            tool_response = f\"\\nSearch Results: {search_tool.run(query)}\"\n",
    "            prompt_messages.append(AIMessage(content=f\"Tool Used: duckduckgo_search\\nResult: {tool_response[:500]}...\")) # Add tool result snippet\n",
    "        except Exception as e:\n",
    "            print(f\"Error using search tool: {e}\")\n",
    "            tool_response = \"\\nSearch tool failed.\"\n",
    "\n",
    "    if \"ChromaDB Retriever Tool\" in available_tools and agent_name == \"Customer\":\n",
    "        try:\n",
    "            logger.info(f\"Using customer retriever tool for query: {query} with customer ID: {customer_id}\")\n",
    "            # Pass query potentially enriched with customer ID context\n",
    "            retriever_query = f\"Info for customer {customer_id}: {query}\"\n",
    "            tool_response = f\"\\nCustomer DB Info: {retriever_tool._run(query=retriever_query, collection_name=customer_id, use_mmr=False)}\"\n",
    "            logger.info(f\"Tool Response: {tool_response}\")\n",
    "            prompt_messages.append(AIMessage(content=f\"Tool Used: ChromaDB Retriever Tool\\nResult: {tool_response}...\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error using customer retriever tool: {e}\")\n",
    "            tool_response = \"\\nCustomer retrieval tool failed.\"\n",
    "\n",
    "    # Final LLM call to generate response based on persona and potential tool output\n",
    "    final_prompt = ChatPromptTemplate.from_messages(prompt_messages)\n",
    "    chain = final_prompt | llm\n",
    "    try:\n",
    "        response = chain.invoke({}) # Query is already in messages\n",
    "        print(f\"{agent_name} Agent Response Snippet: {response.content[:200]}...\")\n",
    "        return {\"agent_response\": response.content, \"error\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"Error during {agent_name} agent LLM call: {e}\")\n",
    "        return {\"error\": f\"{agent_name} agent failed during generation: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Node 5: Reflection ---\n",
    "class ReflectionOutput(BaseModel):\n",
    "    \"\"\"Structured output for the Reflection node.\"\"\"\n",
    "    feedback: str = Field(description=\"Constructive feedback on the response's relevance and correctness relative to the original query.\")\n",
    "    is_final_answer: bool = Field(description=\"True if the answer is satisfactory and directly addresses the original query, False otherwise.\")\n",
    "\n",
    "def reflection_node(state: AgentState):\n",
    "    \"\"\"Reflects on the generated answer, checking relevance and correctness.\"\"\"\n",
    "    print(\"--- Node: Reflection ---\")\n",
    "    if state.get(\"error\"): return {\"is_final\": True} # If error occurred, end the loop\n",
    "\n",
    "    original_query = state['original_query']\n",
    "    agent_response = state['agent_response']\n",
    "    # rewritten_query = state['rewritten_query'] # Could also be used for context\n",
    "\n",
    "    if not agent_response:\n",
    "         print(\"No agent response to reflect on.\")\n",
    "         return {\"reflection\": \"No response generated.\", \"is_final\": True, \"error\": \"Reflection failed: No agent response found.\"}\n",
    "\n",
    "\n",
    "    system_prompt = \"\"\"You are a meticulous quality assurance reviewer. Your task is to evaluate an AI agent's response based on the user's original query.\n",
    "                    Assess the following:\n",
    "                    1.  **Relevance:** Does the response directly address the user's original question?\n",
    "                    2.  **Correctness:** Is the information likely correct (based on general knowledge or provided context)? You don't need to verify external facts exhaustively, but check for obvious flaws or contradictions.\n",
    "                    3.  **Completeness:** Does the response sufficiently answer the question?\n",
    "\n",
    "                    Provide  constructive feedback and determine if the answer is final (good enough) or needs revision/retry. Use the specified JSON format.\n",
    "                    For example, if the original query was 'What is the capital of France?' and the agent response was 'The capital of France is Paris.', your output should be:\n",
    "                    <output>\n",
    "                    {{\n",
    "                        \"feedback\": \"The response is relevant, correct, and complete. It directly answers the question.\",\n",
    "                        \"is_final_answer\": true\n",
    "                    }}\n",
    "                    </output>\n",
    "                    If the original query was 'What is the capital of France?' and the agent response was 'The capital of France is Berlin.', your output should be:\n",
    "                    <output>\n",
    "                    {{\n",
    "                        \"feedback\": \"The response is relevant but incorrect. The capital of France is Paris, not Berlin.\",\n",
    "                        \"is_final_answer\": false\n",
    "                    }}\n",
    "                    </output>\n",
    "                    If the original query was 'What is the capital of France?' and the agent response was 'I don't know.', your output should be:\n",
    "                    <output>\n",
    "                    {{\n",
    "                        \"feedback\": \"The response is not relevant and does not answer the question. It should provide the correct information.\",\n",
    "                        \"is_final_answer\": false\n",
    "                    }}\n",
    "                    </output>\n",
    "                    Your output should be a JSON object with the following fields:\n",
    "                    {{\n",
    "                        \"feedback\": \"<constructive feedback on relevance, correctness, and completeness>\",\n",
    "                        \"is_final_answer\": <true|false>\n",
    "                    }}\n",
    "                    **CRITICAL:** You MUST format your output ONLY as a JSON object that strictly adheres to the above schema. Do NOT include any other text, explanations, or markdown formatting like ```json ``` around the JSON object itself.\n",
    "                    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Original Query: {original_query}\\n\\nAgent Response:\\n{agent_response}\\n\\nPlease evaluate and provide feedback. Your output should be a JSON object as specified above.\")\n",
    "    ])\n",
    "\n",
    "    reflection_chain = prompt | llm\n",
    "    try:\n",
    "        response = reflection_chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"agent_response\": agent_response\n",
    "        })\n",
    "        response = extract_clean_json(response.content)\n",
    "        logger.info(f\"Reflection Chain Response: {response}\")\n",
    "        logger.info(f\"Reflection Chain JSON: {response}\")\n",
    "        if response:\n",
    "            # response = json.loads(json_str)\n",
    "\n",
    "            logger.info(f\"Reflection Chain Response: {response}\")\n",
    "            return {\n",
    "                \"reflection\": response['feedback'],\n",
    "                \"is_final\": response['is_final_answer'],\n",
    "                \"retry_count\": state.get('retry_count', 0) + 1, # Increment retry count\n",
    "                \"error\": None\n",
    "            }\n",
    "        else:\n",
    "            logger.info(\"Reflection output was not valid JSON.\")\n",
    "            return {\n",
    "                \"reflection\": \"Invalid JSON response from reflection.\",\n",
    "                \"is_final\": False,\n",
    "                \"retry_count\": state.get('retry_count', 0) + 1,\n",
    "                \"error\": \"Invalid JSON response from reflection.\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error in Reflection node: {e}\")\n",
    "        # Decide how to handle reflection error - maybe treat as non-final?\n",
    "        return {\"error\": f\"Reflection failed: {e}\", \"is_final\": False, \"retry_count\": state.get('retry_count', 0) + 1}\n",
    "\n",
    "logger.info(\"LangGraph Nodes Defined.\")\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def route_query(state: AgentState):\n",
    "    \"\"\"Routes to the appropriate agent node based on classification.\"\"\"\n",
    "    logger.info(f\"--- Conditional Edge: Routing Query ---\")\n",
    "    if state.get(\"error\"):\n",
    "        logger.info(\"Error detected before routing.\")\n",
    "        return \"error_handler\" # Or END directly\n",
    "\n",
    "    classification = state['classified_agent']\n",
    "    logger.info(f\"Routing based on classification: {classification}\")\n",
    "    if classification == \"Company\":\n",
    "        return \"execute_company\"\n",
    "    elif classification == \"Customer\":\n",
    "        # Add check for customer ID existence\n",
    "        if state.get(\"customer_id\"):\n",
    "             return \"execute_customer\"\n",
    "        else:\n",
    "             logger.info(\"Customer classification but no ID found.\")\n",
    "             # Update state to reflect missing ID issue and go to reflection/end\n",
    "             state[\"error\"] = \"Query classified as Customer, but no Customer ID was provided or found.\"\n",
    "             state[\"agent_response\"] = \"I need a customer ID to answer that question.\"\n",
    "             return \"reflect\" # Go to reflection to potentially end gracefully\n",
    "    elif classification == \"Naive\":\n",
    "        return \"execute_naive\"\n",
    "    else: # Unknown or error during classification\n",
    "        logger.info(\"Classification is Unknown or invalid.\")\n",
    "        state[\"error\"] = f\"Could not determine the right agent for the query (classification: {classification}).\"\n",
    "        state[\"agent_response\"] = \"I'm not sure how to handle that query. Could you please rephrase?\"\n",
    "        return \"reflect\" # Go to reflection\n",
    "\n",
    "def decide_after_reflection(state: AgentState):\n",
    "    \"\"\"Decides whether to end the process or retry based on reflection.\"\"\"\n",
    "    logger.info(f\"--- Conditional Edge: After Reflection ---\")\n",
    "    is_final = state['is_final']\n",
    "    retry_count = state['retry_count']\n",
    "    max_retries = 2 # Set a limit for retries\n",
    "\n",
    "    if state.get(\"error\") and \"Reflection failed\" not in state[\"error\"]: # Handle agent errors first\n",
    "        logger.info(f\"Ending due to execution error: {state['error']}\")\n",
    "        return END # End directly on execution error\n",
    "\n",
    "    logger.info(f\"Reflection result: is_final={is_final}, Retry count={retry_count}\")\n",
    "\n",
    "    if is_final:\n",
    "        logger.info(\"Reflection approved. Ending.\")\n",
    "        return END\n",
    "    elif retry_count >= max_retries:\n",
    "        logger.info(f\"Max retries ({max_retries}) reached. Ending.\")\n",
    "        # Optionally, provide the last reflection feedback\n",
    "        state[\"agent_response\"] += f\"\\n\\n[System Note: Max retries reached. Last feedback: {state.get('reflection', 'N/A')}]\"\n",
    "        return END\n",
    "    else:\n",
    "        print(\"Reflection suggests retry. Looping back to Rewriter.\")\n",
    "        # Add reflection feedback to the original query for context in the next loop? Optional.\n",
    "        # state['original_query'] = f\"{state['original_query']}\\n\\n[Retry Context: Previous attempt failed. Feedback: {state.get('reflection', 'N/A')}]\"\n",
    "        return \"rewrite_query\" # Loop back to the start\n",
    "\n",
    "def question_generator_node(state: AgentState):\n",
    "    \"\"\"Generates relevant follow-up questions based on previous query and response context.\"\"\"\n",
    "    logger.info(\"--- Node: Question Generator ---\")\n",
    "\n",
    "    if state.get(\"error\"):\n",
    "        return {\"suggested_questions\": [], \"error\": state[\"error\"]}\n",
    "\n",
    "    original_query = state['original_query']\n",
    "    agent_response = state['agent_response']\n",
    "    agent_type = state['classified_agent']\n",
    "    customer_id = state.get('customer_id')\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert question generator. Your task is to generate 3-5 highly relevant follow-up questions\n",
    "    based on the original query and the response provided.\n",
    "\n",
    "    The questions should:\n",
    "    1. Help explore the topic in more depth\n",
    "    2. Be directly related to the response content\n",
    "    3. Include specific data points mentioned in the response\n",
    "    4. Focus on the most interesting or valuable aspects\n",
    "    5. Be tailored to the agent type (Company, Customer, or General Knowledge)\n",
    "\n",
    "    For Company questions: Focus on products, services, history, competition, or market position\n",
    "    For Customer questions: Focus on account details, usage patterns, recommendations, or support issues\n",
    "    For General Knowledge: Focus on broader context, practical applications, or recent developments\n",
    "\n",
    "    Format your response as a JSON array of suggested questions:\n",
    "    {\n",
    "        \"suggested_questions\": [\n",
    "            \"Question 1?\",\n",
    "            \"Question 2?\",\n",
    "            \"Question 3?\"\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", f\"\"\"Original Query: {original_query}\n",
    "\n",
    "Agent Type: {agent_type}\n",
    "{f'Customer ID: {customer_id}' if customer_id else ''}\n",
    "\n",
    "Agent Response:\n",
    "{agent_response}\n",
    "\n",
    "Please generate relevant follow-up questions based on this context.\"\"\")\n",
    "    ])\n",
    "\n",
    "    question_chain = prompt | llm\n",
    "\n",
    "    try:\n",
    "        response = question_chain.invoke({})\n",
    "        response_data = extract_clean_json(response.content)\n",
    "\n",
    "        if response_data:\n",
    "            # response_data = json.loads(json_str)\n",
    "            logger.info(f\"Generated {len(response_data.get('suggested_questions', []))} follow-up questions\")\n",
    "            return {\n",
    "                \"suggested_questions\": response_data.get(\"suggested_questions\", []),\n",
    "                \"error\": None\n",
    "            }\n",
    "        else:\n",
    "            logger.warning(\"Question generator output was not valid JSON\")\n",
    "\n",
    "            # Fallback parsing - try to extract questions directly\n",
    "            questions = []\n",
    "            for line in response_data:\n",
    "                # Try to identify numbered questions or questions with question marks\n",
    "                if (line.strip().startswith(('1.', '2.', '3.', '4.', '5.')) or\n",
    "                    '?' in line) and len(line.strip()) > 5:\n",
    "                    questions.append(line.strip())\n",
    "\n",
    "            if questions:\n",
    "                return {\"suggested_questions\": questions[:5], \"error\": None}\n",
    "            else:\n",
    "                return {\n",
    "                    \"suggested_questions\": [],\n",
    "                    \"error\": \"Failed to parse question generator output\"\n",
    "                }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in question generator node: {e}\")\n",
    "        return {\"suggested_questions\": [], \"error\": f\"Question generation failed: {e}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:51:34,632 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "2025-05-05 21:51:34,635 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "2025-05-05 21:51:34,638 - 127360389907520 - llm.py-llm:187 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AgentState(TypedDict):\n",
    "    original_query: str\n",
    "    customer_id: Optional[str]\n",
    "    rewritten_query: str\n",
    "    classified_agent: Literal[\"Company\", \"Customer\", \"Naive\", \"Unknown\"]\n",
    "    agent_response: str\n",
    "    reflection: str\n",
    "    is_final: bool\n",
    "    error: Optional[str]\n",
    "    retry_count: int\n",
    "    suggested_questions: List[str]  # New field for suggested questions\n",
    "\n",
    "logger.info(\"LangGraph State Defined.\")\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"Environment setup starting ......\")\n",
    "llm, retriever_tool, ingest_tool = setup_environment()\n",
    "logger.info(\"Environment setup complete.\")\n",
    "# --- Initialize Tools ---\n",
    "search_tool = SerperDevTool(n_results=2)\n",
    "# Agent 1: Company Agent (Definition)\n",
    "company_agent_def = CrewAgent(\n",
    "    role='Company Information Specialist',\n",
    "    goal='Provide accurate information about the company (e.g., Google) including location, products, services, history, and mission, based on search results and internal knowledge.',\n",
    "    backstory='You are an AI assistant dedicated to representing the company accurately and helpfully to external queries. You use search tools to find the latest public information.',\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent 2: Customer Agent (Definition)\n",
    "customer_agent_def = CrewAgent(\n",
    "    role='Customer Support Agent',\n",
    "    goal='Answer customer-specific questions by retrieving their information from the customer database using their customer ID. Handle queries about plans, purchase history, support tickets etc.',\n",
    "    backstory='You are a helpful customer support agent with access to the customer database. You must use the customer ID provided to retrieve relevant information using your specialized tool.',\n",
    "    tools=[search_tool, retriever_tool], # Has retriever and search\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent 3: Naive Agent (Definition)\n",
    "naive_agent_def = CrewAgent(\n",
    "    role='General Knowledge Assistant',\n",
    "    goal='Answer general knowledge questions or queries that do not fall under specific company or customer information categories. Use search tools to find relevant information online.',\n",
    "    backstory='You are a general-purpose AI assistant capable of answering a wide range of topics by searching the internet.',\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "logger.info(\"CrewAI Agent Definitions Ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Specific node functions calling the generic executor\n",
    "def company_agent_node(state: AgentState):\n",
    "    return execute_agent_node(state, company_agent_def, \"Company\")\n",
    "\n",
    "def customer_agent_node(state: AgentState):\n",
    "    return execute_agent_node(state, customer_agent_def, \"Customer\")\n",
    "\n",
    "def naive_agent_node(state: AgentState):\n",
    "    return execute_agent_node(state, naive_agent_def, \"Naive\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conditional Edges ---\n",
    "\n",
    "def route_query(state: AgentState):\n",
    "    \"\"\"Routes to the appropriate agent node based on classification.\"\"\"\n",
    "    print(f\"--- Conditional Edge: Routing Query ---\")\n",
    "    if state.get(\"error\"):\n",
    "        print(\"Error detected before routing.\")\n",
    "        return \"error_handler\" # Or END directly\n",
    "\n",
    "    classification = state['classified_agent']\n",
    "    print(f\"Routing based on classification: {classification}\")\n",
    "    if classification == \"Company\":\n",
    "        return \"execute_company\"\n",
    "    elif classification == \"Customer\":\n",
    "        # Add check for customer ID existence\n",
    "        if state.get(\"customer_id\"):\n",
    "             return \"execute_customer\"\n",
    "        else:\n",
    "             print(\"Customer classification but no ID found.\")\n",
    "             # Update state to reflect missing ID issue and go to reflection/end\n",
    "             state[\"error\"] = \"Query classified as Customer, but no Customer ID was provided or found.\"\n",
    "             state[\"agent_response\"] = \"I need a customer ID to answer that question.\"\n",
    "             return \"reflect\" # Go to reflection to potentially end gracefully\n",
    "    elif classification == \"Naive\":\n",
    "        return \"execute_naive\"\n",
    "    else: # Unknown or error during classification\n",
    "        print(\"Classification is Unknown or invalid.\")\n",
    "        state[\"error\"] = f\"Could not determine the right agent for the query (classification: {classification}).\"\n",
    "        state[\"agent_response\"] = \"I'm not sure how to handle that query. Could you please rephrase?\"\n",
    "        return \"reflect\" # Go to reflection\n",
    "\n",
    "def decide_after_reflection(state: AgentState):\n",
    "    \"\"\"Decides whether to end the process or retry based on reflection.\"\"\"\n",
    "    print(f\"--- Conditional Edge: After Reflection ---\")\n",
    "    is_final = state['is_final']\n",
    "    retry_count = state['retry_count']\n",
    "    max_retries = 2 # Set a limit for retries\n",
    "\n",
    "    if state.get(\"error\") and \"Reflection failed\" not in state[\"error\"]: # Handle agent errors first\n",
    "        print(f\"Ending due to execution error: {state['error']}\")\n",
    "        return END # End directly on execution error\n",
    "\n",
    "    print(f\"Reflection result: is_final={is_final}, Retry count={retry_count}\")\n",
    "\n",
    "    if is_final:\n",
    "        print(\"Reflection approved. Ending.\")\n",
    "        return END\n",
    "    elif retry_count >= max_retries:\n",
    "        print(f\"Max retries ({max_retries}) reached. Ending.\")\n",
    "        # Optionally, provide the last reflection feedback\n",
    "        state[\"agent_response\"] += f\"\\n\\n[System Note: Max retries reached. Last feedback: {state.get('reflection', 'N/A')}]\"\n",
    "        return END\n",
    "    else:\n",
    "        print(\"Reflection suggests retry. Looping back to Rewriter.\")\n",
    "        # Add reflection feedback to the original query for context in the next loop? Optional.\n",
    "        # state['original_query'] = f\"{state['original_query']}\\n\\n[Retry Context: Previous attempt failed. Feedback: {state.get('reflection', 'N/A')}]\"\n",
    "        return \"rewrite_query\" # Loop back to the start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x73d42db13550>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Build the Graph ---\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"rewrite_query\", rewrite_query_node)\n",
    "workflow.add_node(\"execute_company\", company_agent_node)\n",
    "workflow.add_node(\"execute_customer\", customer_agent_node)\n",
    "workflow.add_node(\"execute_naive\", naive_agent_node)\n",
    "workflow.add_node(\"reflect\", reflection_node)\n",
    "workflow.add_node(\"generate_questions\", question_generator_node)\n",
    "# Optional: Add a specific error handling node if needed\n",
    "# workflow.add_node(\"error_handler\", ...)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"rewrite_query\")\n",
    "\n",
    "# Routing from Rewriter\n",
    "workflow.add_conditional_edges(\n",
    "    \"rewrite_query\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"execute_company\": \"execute_company\",\n",
    "        \"execute_customer\": \"execute_customer\",\n",
    "        \"execute_naive\": \"execute_naive\",\n",
    "        \"reflect\": \"reflect\", # Handle Unknown/Error cases by going directly to reflection\n",
    "        # \"error_handler\": \"error_handler\" # Route explicit errors\n",
    "    }\n",
    ")\n",
    "\n",
    "# Edges from execution nodes to reflection\n",
    "workflow.add_edge(\"execute_company\", \"reflect\")\n",
    "workflow.add_edge(\"execute_customer\", \"reflect\")\n",
    "workflow.add_edge(\"execute_naive\", \"reflect\")\n",
    "\n",
    "# Conditional edge from Reflection (Loop or End)\n",
    "workflow.add_conditional_edges(\n",
    "    \"reflect\",\n",
    "    lambda state: \"generate_questions\" if state[\"is_final\"] else decide_after_reflection(state),\n",
    "    {\n",
    "        \"generate_questions\": \"generate_questions\",\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"generate_questions\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "checkpointer = InMemorySaver()\n",
    "# Compile the graph\n",
    "app = workflow.compile(checkpointer=checkpointer) # Set recursion limit for safety\n",
    "\n",
    "\n",
    "logger.info(\"LangGraph Compiled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agentic_system(query: str, cust_id: Optional[str] = None):\n",
    "    \"\"\"Runs the agentic system with a user query.\"\"\"\n",
    "    initial_state = AgentState(\n",
    "        original_query=query,\n",
    "        customer_id=cust_id,\n",
    "        rewritten_query=\"\",\n",
    "        classified_agent=\"Unknown\", # Start as Unknown\n",
    "        agent_response=\"\",\n",
    "        reflection=\"\",\n",
    "        is_final=False,\n",
    "        error=None,\n",
    "        retry_count=0\n",
    "    )\n",
    "\n",
    "    logger.info(f\"\\n🚀 Starting Agentic System for Query: '{query}'\" + (f\" (Customer ID: {cust_id})\" if cust_id else \"\"))\n",
    "    # config = {\"configurable\": {\"thread_id\": f\"thread_{query[:10]}\"}} # Example thread ID if using checkpointer\n",
    "\n",
    "    try:\n",
    "        # final_state = app.invoke(initial_state, config=config)\n",
    "        config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        final_state = app.invoke(initial_state, config) # Example thread ID if using checkpointer\n",
    "\n",
    "\n",
    "        logger.info(\"\\n🏁 Agentic System Finished!\")\n",
    "        logger.info(\"------ Final State ------\")\n",
    "        # Pretty print relevant parts of the final state\n",
    "        logger.info(f\"Original Query: {final_state['original_query']}\")\n",
    "        if final_state.get('rewritten_query'): print(f\"Rewritten Query: {final_state['rewritten_query']}\")\n",
    "        if final_state.get('classified_agent'): print(f\"Agent Used: {final_state['classified_agent']}\")\n",
    "        if final_state.get('error'):\n",
    "            logger.info(f\"Error Occurred: {final_state['error']}\")\n",
    "        logger.info(f\"\\nFinal Response:\\n{final_state['agent_response']}\")\n",
    "        if final_state.get('reflection') and not final_state.get('is_final') and final_state.get('retry_count') > 0:\n",
    "             logger.info(f\"\\nLast Reflection Feedback (Process Ended): {final_state['reflection']}\")\n",
    "        # Add display of suggested questions if present\n",
    "        if final_state.get('suggested_questions'):\n",
    "            logger.info(\"\\n✨ Suggested follow-up questions:\")\n",
    "            for i, question in enumerate(final_state['suggested_questions'], 1):\n",
    "                logger.info(f\"  {i}. {question}\")\n",
    "        return final_state\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.info(f\"\\n💥 An unhandled error occurred during graph execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Example Queries ---\n",
    "# run_agentic_system(\"Tell me about my purchase history for cust123\")\n",
    "# run_agentic_system(\"What was my last support ticket about?\", cust_id=\"cust123\") # Providing ID separately\n",
    "# run_agentic_system(\"can you tell me about the plan for customer cust456 please?\")\n",
    "# run_agentic_system(\"Who invented the telephone?\")\n",
    "# run_agentic_system(\"hwat is googles mission sttement?\") # Test spelling correction\n",
    "# run_agentic_system(\"Tell me about cust999\") # Test non-existent customer ID (if retriever handles it)\n",
    "# run_agentic_system(\"This query is confusing and makes no sense.\") # Test unknown/retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewriter Output: {'rewritten_query': 'Where is the main Google office located?', 'agent_classification': 'Company', 'extracted_customer_id': None}\n",
      "--- Conditional Edge: Routing Query ---\n",
      "Routing based on classification: Company\n",
      "--- Node: Execute Company Agent ---\n",
      "Company Agent Response Snippet: <think>\n",
      "Okay, so I need to figure out where the main Google office is located. Hmm, I'm not exactly sure about this off the top of my head. Let me think through it step by step.\n",
      "\n",
      "First, I know that Go...\n",
      "--- Node: Reflection ---\n",
      "--- Conditional Edge: After Reflection ---\n",
      "Reflection result: is_final=False, Retry count=1\n",
      "Reflection suggests retry. Looping back to Rewriter.\n",
      "Rewriter Output: {'rewritten_query': 'Where is the main Google office located?', 'agent_classification': 'Company', 'extracted_customer_id': None}\n",
      "--- Conditional Edge: Routing Query ---\n",
      "Routing based on classification: Company\n",
      "--- Node: Execute Company Agent ---\n",
      "Company Agent Response Snippet: <think>\n",
      "Okay, so I need to figure out where the main Google office is located. Hmm, I'm not exactly sure about this off the top of my head, but I know Google has a lot of offices around the world. Let...\n",
      "--- Node: Reflection ---\n",
      "--- Conditional Edge: After Reflection ---\n",
      "Reflection result: is_final=False, Retry count=2\n",
      "Max retries (2) reached. Ending.\n",
      "Rewritten Query: Where is the main Google office located?\n",
      "Agent Used: Company\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'original_query': 'Where is the main Google office located?',\n",
       " 'customer_id': None,\n",
       " 'rewritten_query': 'Where is the main Google office located?',\n",
       " 'classified_agent': 'Company',\n",
       " 'agent_response': \"<think>\\nOkay, so I need to figure out where the main Google office is located. Hmm, I'm not exactly sure about this off the top of my head, but I know Google has a lot of offices around the world. Let me think through how I can approach this.\\n\\nFirst, I remember that Google's headquarters are in Mountain View, California. That makes sense because Mountain View is a well-known city with a nice mountain range, which probably reflects their location near Google's offices. But wait, there might be other offices too. Maybe some of them are in different cities or even countries?\\n\\nI think Google has offices in multiple countries, not just the US and Canada. I've heard about offices in places like Tokyo, Hong Kong, and maybe even some European cities. Let me try to recall any specific locations I know.\\n\\nIn Japan, I believe there's a Google office near the Tokyo Skytree. That sounds familiar because I've seen pictures of Google there. So that's one location in Japan. Then there's Hong Kong, which is part of China. I think Google has an office there too, maybe near the Chinese Post Office or something like that.\\n\\nI also remember hearing about a Google office in London. It might be near the British Museum since that's a significant landmark and Google often collaborates with institutions like the British Museum. So London could be another location.\\n\\nAre there any offices in other countries? Maybe in Australia, but I'm not sure where exactly. I think there are some offices in New South Wales or Queensland, but I don't recall their exact locations. Similarly, in Germany, maybe there's an office near a major university or business complex.\\n\\nI should also consider if Google has any offices outside of the US and Canada. Maybe in Europe, Australia, or even parts of Asia. But without specific names, it might be hard to pin down exactly where each office is located.\\n\\nWait, I think I've heard about a Google office in New York City. It's probably near the Times Square area because that's a major business hub and Google has been around for decades. So New York could be another location.\\n\\nPutting this all together, I can list out the locations I know: Mountain View, California; Tokyo Skytree, Japan; Chinese Post Office or nearby in Hong Kong; British Museum in London; possibly New South Wales or Queensland in Australia; and Times Square in New York City.\\n\\nI should make sure these are accurate. Let me check a bit more about each location to confirm:\\n\\n- Mountain View, CA: Definitely the headquarters.\\n- Tokyo Skytree: Yes, that's where Google is based there.\\n- Hong Kong: I think it's near the Chinese Post Office or some other significant building.\\n- British Museum in London: That's correct; Google collaborates with institutions like this.\\n- New South Wales or Queensland: Maybe near a university or business complex. I'm not sure of the exact location, but it's somewhere in Australia.\\n- Times Square, NY: Yes, that's where the headquarters are located.\\n\\nI think these are the main locations I can confidently say about Google's offices based on my current knowledge. There might be more details or specific addresses, but this gives a good overview of where they are located globally.\\n</think>\\n\\nGoogle has its headquarters and multiple offices across various countries and cities around the world. Here is an organized list of the key locations:\\n\\n1. **Mountain View, California**: The main headquarters of Google.\\n2. **Tokyo Skytree**: A Google office in Tokyo, near the Tokyo Tower.\\n3. **Hong Kong**: A Google office near the Chinese Post Office or other significant buildings.\\n4. **British Museum in London**: Google collaborates with institutions like this.\\n5. **New South Wales or Queensland**: Possibly located near a university or business complex.\\n6. **Times Square, New York City**: The headquarters are situated here.\\n\\nThese locations reflect Google's global presence and collaboration across different regions.\",\n",
       " 'reflection': '',\n",
       " 'is_final': False,\n",
       " 'error': \"Reflection failed: 'dict' object has no attribute 'content'\",\n",
       " 'retry_count': 2}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_agent = run_agentic_system(\"Where is the main Google office located?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
